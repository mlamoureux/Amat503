{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMAT503:  Lecture 05\n",
    "\n",
    "January 23, 2018.\n",
    "\n",
    "Michael Lamoureux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HEADS' UP!\n",
    "\n",
    "I will be using [Jupyter notebooks](https://jupyter.org) in this classroom, to combine text, math, and graphics. \n",
    "\n",
    "Students can access Jupyter at [ucalgary.syzygy.ca](https://ucalgary.syzygy.ca)\n",
    "\n",
    "An eBook on how to use syzygy is here: [intro.syzygy.ca](http://intro.syzygy.ca)\n",
    "\n",
    "Lecture notes, code, assignments, etc are available on a git repo: [github.com/mlamoureux](https://github.com/mlamoureux)\n",
    "\n",
    "The textbnook for the course is available electronically\n",
    "[here](https://ucalgary.summon.serialssolutions.com/#!/#!%2Fsearch%3FbookMark=ePnHCXMwhZ3bCoJAEIYNvCjrGcq6CLoQFMLoNjN6gO4H6QBSWLRrh7fvH2ddC4QuxQ_Fw87-M7v7r-e4yFuPHXFTYoMxiNIYSbV43SxC_EMRdyEeV8mQFIlTMnQJOl9ogW5dIGGvc2RuPcdf52hBkJD-M-PNGLSvvzQdvs3AcfW9RDQdbdJdsg2MheubTAWEeBZXHLHXXiBEs6iByiIveOdjKvcR8YIWZChLhHZ2au87M-EzdUbIQTjSih6XahhT0c_zgR0Lq7ITslyyTPPMYKbC1FGfqkuZaZiUrhLId-gLgEMBZfCYbuI8QVFYjZPy9pmTVkC_dCvULKiyqL2VgbiIcrja03KI5h3PGfr3aj8nd5KS)\n",
    "\n",
    "or [here](https://proquest-safaribooksonline-com.ezproxy.lib.ucalgary.ca/9780470183113?uicode=ucalgary).\n",
    "Thanks to Phil for pointing this out. \n",
    "\n",
    "\n",
    "One of the links should take any student to the ucalgary login page and then to the web version of the book after they successfully login."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Some startup commands\n",
    "\n",
    "%matplotlib inline\n",
    "from numpy import * \n",
    "from scipy import *\n",
    "from matplotlib.pyplot import *\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Energy of a signal.\n",
    "- Signal to noise ratio, energy\n",
    "- decibels\n",
    "- Modifying energy for image data, RGB spacce, etc\n",
    "- Fourier transforms\n",
    "- Haar transform, first steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy\n",
    "\n",
    "Given a signal $f(t)$ as a function of time, we define its energy as the integral\n",
    "$$E = \\int_{-\\infty}^\\infty |f(t)|^2 \\, dt.$$\n",
    "If the signal is on a fixed inteval $[0,L]$ we could instead define the energy as\n",
    "$$E = \\int_0^L |f(t)|^2 \\, dt.$$\n",
    "For a sampled signal $f(0), f(\\Delta t), f(2\\Delta t), \\ldots$ the appropriate definition is\n",
    "$$ E = \\sum_{n=0}^\\infty |f(k)|^2 \\Delta t$$\n",
    "although in many cases people will drop the constant $\\Delta t$ in the sum.\n",
    "\n",
    "Since **energy** is a physical term, we should be careful to indicate why these sums or integrals are like enerrgy. It is more accurate to say they are proportional to the energy in certain types of signals. For instance, if $f(t)$ is measuring electrical voltage $V$ across a resistor, the amount of current $I$ flowing through the resistor is given by Ohm's law, $$V = IR$$, where $R$ is the resistance of the device (resistor). The power is then\n",
    "$$ P = IV = V^2/R, $$\n",
    "and the energy is the amount of power multiplied by the length of time you are using that power,\n",
    "$$ E = (V^2/R)*T.\n",
    "\n",
    "For instance, a standard incadescent bulb uses 100 watts (a measure of power) and if you light it up for 10 hours, that uses 1000 watt-hours, or one kilowatt-hour. Your utlilty company changes you for the total amount of energy you use, in this case one kilo-watt hour.\n",
    "\n",
    "The point is, our signal energy $E = \\int_0^L |f(t)|^2 \\, dt$ is proportional to $f^2$, or voltage squared, multiplied by the length of time. So up to some scaling factor ($1/R$), it is the physical energy.\n",
    "\n",
    "Other physical energies we see in real life are kinetic energy $(1/2)mv^2$ of a moving object with mass $m$ and velocity $v$, or the potential energy $(1/2)k x^2$ of a linear spring displaced by $x$ units from rest. ($k$ is the spring constant in Hooke's law). or Einstein's $E= mc^2$. The point is, in all these energy calculation, there is a variable quantity (voltage, velocity, displacement) that appears as a square. \n",
    "\n",
    "So we use the square in our definition of signal energy. Note the square root of energy is then our usual $L^2$ norm for functions. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjustments for signals\n",
    "\n",
    "This energy definition makes sense for things like electical signals, where $f(t)$ measures something like voltage, and where $f(t) = 0$ is the \"no signal\" state. \n",
    "\n",
    "However, some signals might have a non-zero resting state. For instance, a B/W image is often recorded as an array of pixels with numerical values stored as an integer 0 to 255. (i.e. it has 8 bits of information for each pixel.) There is no particular reason why 0 is a special value, it just means \"black.\" 255 just means \"white.\" An all white image seems to have about the same information as an all black image. So maybe it makes more sense to measure the variation about the mean as the enegy. That is, we might define\n",
    "$$E = \\int_0^L | f(t) - f_{mean} |^2 dt$$\n",
    "where the mean is given as the average value of f,\n",
    "$$f_{mean} = \\frac{1}{L}\\int_0^L f(t) dt.$$\n",
    "\n",
    "For a sampled signal,\n",
    "$$E = \\sum_1^N | f(n) - f_{mean} |^2 $$\n",
    "where the mean is given as the average value of f,\n",
    "$$f_{mean} = \\frac{1}{N}\\sum_0^N f(n) .$$\n",
    "\n",
    "For a B/W image with a $M\\times N$ array of pixels, we can use\n",
    "$$E = \\sum_{m,n=1}^{M,N} | f(m,n) - f_{mean} |^2 $$\n",
    "where the mean is given as the average value of f,\n",
    "$$f_{mean} = \\frac{1}{MN}\\sum_{m,n=1}^{M,N} f(m,n) .$$\n",
    "\n",
    "For a colour image, you might like to take just the Energy of each of the three channels, and add them up. (Usually substracting the mean of each.)\n",
    "\n",
    "For other colour representations, you might want to think carefully about what you are measuring! (Sometimes easier just to covert to RGB space.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal to noise\n",
    "\n",
    "In signal processing, we often use a very simple model to analyze noise in a signal. Think of music, with static in it (from a scratchy record, a bad radio reception, and so on. ) The original signal $s(t)$ is contaminated with some noise $n(t)$ which is added to the signal, resulting in a noisy sinal\n",
    "$$f(t) = s(t) + n(t).$$\n",
    "\n",
    "The signal-to-noise ratio is just a measure\n",
    "$$SNR = \\frac{\\mbox{Energy of signal s}}{\\mbox{Energy of noise n}}.$$\n",
    "\n",
    "What's nice about using a ratio is that we don't have to worry about any proportionality constants that came up in our various definitions of energy -- they get cancelled out anyway. \n",
    "\n",
    "It is common to state the SNR in decibels, as\n",
    "$$ SNR = 10*\\log_{10} \\frac{\\mbox{Energy of signal s}}{\\mbox{energy of noise n}} \\mbox{decibels}. $$\n",
    "So for instance, if the energy of the noise goes up by a factor of 2, the ration goes down by a factor of 2, so the SNR decreases by about 3 dB. ($10*\\log_{10} (1/2) = 3.01$)\n",
    "\n",
    "Note that decibels are used all over the place, including measuring the intensity of sounds we here. Keep in mind it is the log of a ratio, so you are always measuring the signal energy relative to something. \n",
    "\n",
    "For instance, when we said the loud sound of a motorcycle is at 80 dB, that is relative to the softest sound a human can hear (which is defined as 0 dB). Note it has $10^8$ times the energy. (Can you see why?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations of SNR\n",
    "\n",
    "The signal to noise ratio is useful for situations where you are measuring additive noise. This is often the case for electrical signals, and also the error model for many statistical experiments.\n",
    "\n",
    "It is not alway appropriate, though. Suppose you have a signal $s(t)$ that gets recorded as a delay version, so the recorded signal is $$f(t) = s(t-\\Delta t).$$\n",
    "Depending on the size of $\\Delta t$, you might not really case about that error. But our noise model forces it to look like we have noise given as $$n(t) = s(t-\\Delta t) - s(t)$$ which could be quite large. (It looks like a derivative of $s$.)\n",
    "\n",
    "Or what if your recorded signal was just modifying $s(t)$ by some constant, or a linear transform like\n",
    "$$f(t) = .9 s(t) + 1.2.$$\n",
    "Again, you might not care about such errors, but the additive noise model with indicate a significant level of noise.\n",
    "\n",
    "### Moral:\n",
    "Be careful about how you define your SNR, use something that is appropriate to the problem at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier transform\n",
    "\n",
    "- how much do the students know already?\n",
    "- complex numbers? Complex exponentials?\n",
    "- on a discrete space\n",
    "- on an interval\n",
    "- on the real line\n",
    "- connection to convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex numbers\n",
    "\n",
    "We use complex numbers because it makes our life easier. In particular, algebra becomes easier. For instance, any polynomial can be factored as a product of linear terms $x-x_o$, where $x_o$ is called a root of the polynomial. For example,\n",
    "$$ x^2 + 1 = (x+i)(x-i)$$\n",
    "factors the quadratic into two linear factors with roots $\\pm i$. Notice, though, that we started with a polynomial involving only real coefficients (in fact, integers), but the roots are imaginary.\n",
    "\n",
    "It is also true that a polynomial with complex coefficients, like $ix^3 + (1+i)x$ can be factored with complex roots. So the complex numebers are rich enough to factor polynomials with coefficients that are either real or complex. \n",
    "\n",
    "You should have seen complex numbers by now in other classes. A quick reminder though:\n",
    "- every complex number can be written as a real plus imaginary part, like $2 + 3i$.\n",
    "- you can think of complex numbers as living on the 2D plane, with x and y coordinates for real and imaginary parts\n",
    "- you can also represent a complex number in polar form, $r\\cdot\\cos(\\theta) + i\\cdot r\\cdot\\sin(\\theta)$, where $r$ is distance from the origin, and $\\theta$ is the polar angle in the 2D plane\n",
    "- we often write $e^{i\\theta} = \\cos(\\theta) + i\\cdot\\sin(\\theta)$\n",
    "- you can add, subtract, multiply and divide any two complex numbers. (we say it is a \"field\")\n",
    "\n",
    "As an example of why we like complex numbers, notice the exponential property for sums:\n",
    "$$ e^{i(\\theta_1 + \\theta_2)} = e^{i\\theta_1}e^{i\\theta_2}.$$\n",
    "Easy to remember, right?\n",
    "\n",
    "However, if you convert this to real and imaginary parts using sines and cosines as defined above, and multiply everything together (i.e. do some algebra), the real part of the equation says\n",
    "$$ \\cos(\\theta_1 + \\theta_2) = \\cos(\\theta_1)\\cos(\\theta_2) - \\sin(\\theta_1)\\sin(\\theta_2)$$\n",
    "and the imaginar part says\n",
    "$$ \\sin(\\theta_1 + \\theta_2) = \\cos(\\theta_1)\\sin(\\theta_2) + \\sin(\\theta_1)\\cos(\\theta_2).$$\n",
    "So we get the familiar, but hard to remember trig identities. Point is, it is easier to remember the exponential rule rather than the trig rules. So complex wins. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex-valued functions.\n",
    "\n",
    "We will be using functions on the real line that happen to take complex values. \n",
    "\n",
    "So don't get this confused with complex analysis, which involves functions defined on the complex plane. (Like $F(z) = z^2 - 23$, with $z$ complex.) We aren't doing that. \n",
    "\n",
    "We want to look at functions defined with a real variable $t$, like\n",
    "$$f(t) = t^2 + i\\cdot\\cos(t)$$\n",
    "or \n",
    "$$g(t) = 1/t + i\\cdot\\tan(t).$$\n",
    "The point is, the functions are defined using a real variable $t$ but evaluate as complex numbers. So, in these examples\n",
    "$$f (0) = 0, f(\\pi) = \\pi^2 + i\\cdot\\cos(\\pi) = \\pi^2 - i.$$\n",
    "Now, functions like this you can add, subtract, multiply and divide, just by treating them pointwise like complex numbers. You can also take derivatives and integrals, by doing the real and imaginary parts separately. So, in these examples above, we can compute the derivatives as\n",
    "$$f'(t) = \\frac{d}{dt} (t^2) + i\\cdot \\frac{d}{dt} (\\cos(t)) = 2t - i\\cdot\\sin(t),$$ and\n",
    "$$g'(t) = \\frac{d}{dt} (1/t) + i\\cdot \\frac{d}{dt} (\\tan(t)) = -1/t^2 + i\\cdot\\sec^2(t).$$\n",
    "Similarly, for antiderivatives, do the real and imaginary parts separately, so\n",
    "$$\\int f(t) dt = \\int t^2 dt + i\\cdot \\int \\cos(t) dt  = t^3/3 + i\\cdot\\sin(t) + C,$$ and\n",
    "$$\\int g(t) dt = \\int (1/t) dt + i\\cdot \\int \\tan(t) dt = \\ln(t) + i\\cdot\\ln(\\cos(t)) + C.$$\n",
    "And yes, the arbitrary constant $C$ should be a complex constant.\n",
    "\n",
    "Now, since we will use it so often in Fourier series, we should compute the derivative and antiderivative of the complex exponential:\n",
    "$$\\frac{d}{dt} e^{2\\pi i t} = \\frac{d}{dt} \\cos(2\\pi t) + i\\cdot \\frac{d}{dt} \\sin(2\\pi t) \n",
    "= - 2\\pi\\sin(2\\pi t) + 2\\pi i \\cos(2\\pi t) = 2\\pi i e^{2\\pi i t}.$$\n",
    "\n",
    "The important fact is the derivative of the exponential is the same exponential, times a constant that was in the exponent:\n",
    "$$\\frac{d}{dt} e^{2\\pi i t} = 2\\pi i e^{2\\pi i t}.$$\n",
    "(In this case, the constant is $2\\pi i$.)\n",
    "\n",
    "For the antiderivative\n",
    "$$\\int e^{2\\pi i t} dt = \\frac{e^{2\\pi i t}}{2\\pi i } + C$$\n",
    "which just says the antiderivative of an exponential is the same exponential, divided by that constant appearing in the argument. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sets of functions.\n",
    "\n",
    "A few students commented that I use a lot of notation for different collections of functions. Sorry about that. It's pretty standard notation, so it is good to get used to. \n",
    "\n",
    "### $C([0,1])$.\n",
    "\n",
    "This is the set of continuous functions on the interval $[0,1]$. It is sort of ambiguous as to whether we mean real-valued functions, or complex-valued functions. But in this class, you should assume complex, unless we say otherwise.\n",
    "\n",
    "This space has a norm on it, which is a way to measure how big the function is. It is call the supremum norm, or max norm, defined as\n",
    "$$ || f ||_\\infty  = \\max_{0\\leq t \\leq 1} |f(t)|.$$\n",
    "That is, it is the maximum of the absolute value of the function.\n",
    "\n",
    "We can put an inner product on this space, just like we do for vectors. The inner product of two functions $f,g$ is given as an integral:\n",
    "$$ \\langle f,g \\rangle = \\int_0^1 f(t) \\overline{g(t)} dt, $$\n",
    "where this notation $\\overline{g(t)}$ means we take the complex conjugate of the numbers $g(t)$. \n",
    "\n",
    "We do need this complex conjugate in order to get the Cauchy-Swartz inequality to work out, which says\n",
    "$$ | \\langle f,g \\rangle | \\leq \\sqrt{\\langle f,f \\rangle} \\sqrt{\\langle g,g \\rangle}.$$\n",
    "\n",
    "You can think of the quantity $\\sqrt{\\langle f,f \\rangle}$ as another way of measuring the size of a function. Roughly speaking, $\\langle f,f \\rangle$ is the average value of the absolute value of f squared, on the interval $[0,1]$. Which we normalize by then taking the square root. This defines another kind of norm on $C([0,1])$, as\n",
    "$$ || f ||_2 = \\sqrt{\\langle f,f \\rangle} = \\int_0^1 |f(t)|^2 dt.$$\n",
    "\n",
    "This is called the 2-norm, and it behaves a lot like the Euclidean norm in regular vector spaces. \n",
    "\n",
    "### $L^2([0,1])$\n",
    "\n",
    "This is called the el-two space of functions on the interval $[0,1]$. It includes all the continuous functions above, as well as any function that can be written as a limit of a sequence of continuous functions, using the 2-norm for computing the limit. So it includes even discontinuous functions, like piecewise continuous function whose 2-norm is finite. (e.g. like a step function.) It even includes functions that might blow up mildly, like $f(t) = t^{-1/4}$.\n",
    "\n",
    "It also uses the same inner product as we defined on $C([0,1])$. \n",
    "\n",
    "It is called a Hilbert space, named after mathematician David Hilbert. It was more or less invented to solve mathematical problems in quantum physics. \n",
    "\n",
    "### $l^2(\\mathbf{N})$\n",
    "\n",
    "This is the set of sequences of complex numbers $\\{ x_1, x_2, x_3, \\ldots \\}$ whose sum of squares is finite. That is, \n",
    "$$ \\sum_1^\\infty |x_n|^2< \\infty.$$ Notice this means the limit of the sequence has to be zero. (as $n$ goes to infinity). You can think of this space as the set of functions $n\\mapsto x_n$ from the natural numbers $\\mathbf{N}$ to the complex numbers, whose values squared add up to a finite number.\n",
    "\n",
    "We use the squares because then we can define an inner project, as \n",
    "$$\\langle \\mathbf{x}, \\mathbf{y} \\rangle =\\sum_1^\\infty x_n \\overline{y_n}.$$\n",
    "Again, we get the Cauchy-Swartz inequality \n",
    "$$| \\langle \\mathbf{x}, \\mathbf{y} \\rangle |  \\leq \\sqrt{\\langle \\mathbf{x}, \\mathbf{x} \\rangle}\n",
    "\\sqrt{\\langle \\mathbf{y}, \\mathbf{y} \\rangle}$$\n",
    "and we define the el-two norm as\n",
    "$$ || \\mathbf{x} ||_2 = \\sqrt{\\langle \\mathbf{x}, \\mathbf{x} \\rangle} = \\sqrt{ \\sum_1^\\infty |x_n|^2}.$$\n",
    "\n",
    "### $l^2(\\mathbf{Z})$\n",
    "\n",
    "This is the set of double infinite sequences of complex numbers $\\{ \\ldots x_{-2}, x_{-1}, x_0, x_1, x_2, x_3, \\ldots \\}$ whose sum of squares is finite. That is, \n",
    "$$ \\sum_{-\\infty}^\\infty |x_n|^2< \\infty.$$  You can think of this space as the set of functions $n\\mapsto x_n$ from the integers $\\mathbf{Z}$ to the complex numbers, whose values squared add up to a finite number.\n",
    "\n",
    "We use the squares because then we can define an inner project, as \n",
    "$$\\langle \\mathbf{x}, \\mathbf{y} \\rangle =\\sum_{-\\infty}^\\infty x_n \\overline{y_n}.$$\n",
    "Again, we get the Cauchy-Swartz inequality \n",
    "$$| \\langle \\mathbf{x}, \\mathbf{y} \\rangle |  \\leq \\sqrt{\\langle \\mathbf{x}, \\mathbf{x} \\rangle}\n",
    "\\sqrt{\\langle \\mathbf{y}, \\mathbf{y} \\rangle}$$\n",
    "and we define the el-two norm as\n",
    "$$ || \\mathbf{x} ||_2 = \\sqrt{\\langle \\mathbf{x}, \\mathbf{x} \\rangle} = \\sqrt{ \\sum_{-\\infty}^\\infty |x_n|^2}.$$\n",
    "\n",
    "Although the spaces $l^2(\\mathbf{N})$ and $l^2(\\mathbf{Z})$ are similar, we will like the $\\mathbf{Z}$ one better, because the set of integers is a group under addition. (So Fourier analysis works nicely here.)\n",
    "\n",
    "### $l^2( \\{1,2,3,\\ldots, n\\}) = \\mathbf{C}^n$\n",
    "\n",
    "We can think of $l^2( \\{1,2,3,\\ldots, n\\})$ as the set of finite sequences $\\{ x_1, x_2, x_3, \\ldots, x_n \\}$ of complex numbers. This is the same as the set of n-dimensional complex vectors. The last two examples above show us how to define inner products (just use finite sums, not infinite sums), and the el-two norm. It is exactly the finite dimensional complex vector space $\\mathbf{C}^n$ that you learned about in linear algebra classes. \n",
    "\n",
    "It will be convenient later to start our indices as zero, so we have\n",
    "$$l^2( \\{0, 1,2,\\ldots, n-1\\}) = \\mathbf{C}^n.$$\n",
    "In this case, we can treat the set $\\{0, 1,2,\\ldots, n-1\\}$ as the integers modulo $n$, and define addition, subtraction of integers modulo $n$. So again, we get a group, and Fourier analysis will work here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier tranforms\n",
    "\n",
    "The theory of Fourier transforms is a rich and deep area of mathematics, going back to 1805 when Joseph Fourier was showing how to solve the heat equation. (He wanted to help build cannons, which get really hot during construction.) The motivation is that somehow a Fourier transform changes a hard problem (like PDEs) into an easly problem (like algebra). \n",
    "\n",
    "The basic idea is you have a function on one space, and you transform it into a function on another space. Physically, this often means something like transforming a signal in time into a signal in frequency. (e.g. music is represented as a sum of tones at various frequencies.) It also means you can transform back (a set of frequencies can be reconstructed into music.) Amazing properties hold, like the el-two norm is preserved, inner products are preserved, convolution becomes simple multiplication, and vice versa. \n",
    "\n",
    "The first step is to know what spaces are involved. The 3 basic ones we want are:\n",
    "- $[0,1] \\leftrightarrow \\mathbf{Z}$\n",
    "- $\\mathbf{R} \\leftrightarrow \\mathbf{R}$\n",
    "- $\\{0, 1,2,\\ldots, n-1\\} \\leftrightarrow \\{0, 1,2,\\ldots, n-1\\}$\n",
    "\n",
    "But you can make combinations of these spaces, and the transforms do the natural thing. For instance, functions on a square will map to functions on a product of the integers:\n",
    "- $[0,1]\\times [0,1] \\leftrightarrow \\mathbf{Z}^2$\n",
    "\n",
    "But lets get started with the first three. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier transform on $[0,1]$\n",
    "\n",
    "Start with a function $f(t)$ on the interval $[0,1]$. Continuous, or piecewise continuous will work. Its Fourier transform is defined as a function on the integers $\\mathbf{Z}$, and is denoted $\\hat{f}$. We define $hat{f}$ as\n",
    "$$\\hat{f}(n) = \\int_0^1 f(t) e^{- 2\\pi i nt} dt = \\langle f, e^{2\\pi i nt} \\rangle,\n",
    "\\mbox{ for any integer $n$}. $$\n",
    "So $\\hat{f}$ is computed by taking inner products with various complex exponential functions $e^{2\\pi i nt}$. Notice the $n$ in the argument of the exponential. \n",
    "\n",
    "Now, these complex exponentials are orthogonal to each other: that is, their inner products are zero. We did this in class, but quickly we can compute the inner product of two of them as follows:\n",
    "$$\\langle e^{2\\pi i n t}, e^{2\\pi i m t} \\rangle = \\int_0^1 e^{2\\pi i n t}e^{-2\\pi i m t} dt\n",
    "= \\int_0^1 e^{2\\pi i (n-m) t} dt = \\frac{e^{2\\pi i (n-m) t}}{2\\pi i (n-m)}\\large|_{t=0}^{t=1} = 0.$$\n",
    "And this works whenever $n\\neq m$.\n",
    "\n",
    "Now, what if $f$ is a rather simple function, say the sum of a finite number of complex exponentials:\n",
    "$$ f(t) = \\sum_{k=-N}^N a_k e^{2\\pi i kt}. $$\n",
    "We can compute its Fourier transform using linearity of the inner product, so\n",
    "$$ \\hat{f}(n) = \\langle f,  e^{2\\pi i nt} \\rangle = \\sum_k a_k \\langle e^{2\\pi i kt}, e^{2\\pi i nt} \\rangle = a_n,$$\n",
    "where that sum collapses since the inner product of two exponentials is zero (see above) except when $k=n$.\n",
    "\n",
    "So the Fourier transform of $f$ pulls out the coefficient in the sum. In other words, for these finite sums, we can write\n",
    "$$f (t) = \\sum_{n=-N}^N \\hat{f}(n) e^{2\\pi i nt}.$$\n",
    "That is, function $f$ on the interval is recovered directly from its Fourier transform $\\hat{f}$ which was a function on the integers. \n",
    "\n",
    "### Magic of analysis\n",
    "\n",
    "By taking limits, we can actually show that for any function in $L^2([0,1])$ that \n",
    "$$ f(t) = \\lim_{N\\rightarrow\\infty} \\sum_{n=-N}^N \\hat{f}(n) e^{2\\pi i nt},$$ where we are taking the limit as functions in the normed space $L^2([0,1])$. So we can recover the function $f$ from its Fourier coefficients. \n",
    "\n",
    "Actually, most mathematicians worry a lot about whether this limit holds points. (Often, it does!). \n",
    "\n",
    "### What about inner products?\n",
    "\n",
    "Well, the trick is again to check first by using simple polynomials in exponentials. So suppose we have functions $f,g$ which are just finite sums of those complex exponentials. From above, we can write them in terms of their Fourier coefficients, so\n",
    "$$f(t) = \\sum_{n=-N}^N \\hat{f}(n) e^{2\\pi i nt}, \\quad g (t) = \\sum_{m=-N}^N \\hat{g}(m) e^{2\\pi i mt}.$$\n",
    "Taking inner products, we have\n",
    "$$\\langle f,g \\rangle = \\langle \\sum_{n=-N}^N \\hat{f}(n) e^{2\\pi i nt}, \\sum_{m=-N}^N \\hat{g}(m) e^{2\\pi i mt} \\rangle\n",
    "= \\sum_{m,n} \\hat{f}(n)\\overline{\\hat{g}(m)} \\langle e^{2\\pi i nt}, e^{2\\pi i mt} \\rangle = \n",
    "\\sum_n \\hat{f}(n)\\overline{\\hat{g}(m)},$$\n",
    "since those complex exponentials all are orthogonal to each other and we get a bunch of zeros except when $n=m$.\n",
    "But now we notice that this sum $\\sum_n \\hat{f}(n)\\overline{\\hat{g}(m)}$ is just the inner product in the sequence space $l^2(\\mathbf{Z})$, so we do have\n",
    "$$\\langle f,g \\rangle = \\langle \\hat{f},\\hat{g} \\rangle. $$\n",
    "That is, the Fourier transform is preserving the inner product of functions.\n",
    "\n",
    "### Again, magic of analysis\n",
    "\n",
    "By taking limits, we can actually show that for any two functions $f,g$ in $L^2([0,1])$ that \n",
    "$$\\langle f,g \\rangle = \\langle \\hat{f},\\hat{g} \\rangle. $$ \n",
    "That is, the Fourier transform is preserving the inner product of functions.\n",
    "\n",
    "Of course, the el-two norm is preserved, since it comes from the inner product. So\n",
    "$$ ||f||_2 = \\sqrt{\\langle f,f \\rangle} = \\sqrt{\\langle \\hat{f},\\hat{f} \\rangle} = ||\\hat{f}||_2.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier transform on $\\mathbf{Z}$\n",
    "\n",
    "Start with a function on $\\mathbf{Z}$, that is, a double sequence $\\{ \\ldots, a_{-1}, a_0, a_1, a_2, \\ldots \\}$. How do you get a functon on the interval? Easy, like we did as above, define the Fourier transform of the sequence as a linear combination of exponentials:\n",
    "$$\\hat{a}(t) = \\sum_n a_n e^{2\\pi i n t}. $$\n",
    "To prove the analogous results (recovering sequence $a$ from its Fourier transform $\\hat{a}$, preserving inner products, preserving el-two norm), just start with a sequence that has only finitely many non-zero terms. It all goes through sweetly, from the orthogonality of the complex exponentials. \n",
    "\n",
    "Take limits to get the results in $l^2(\\mathbf{Z})$.\n",
    "\n",
    "So we are done. The FT of a sequence in $l^2(\\mathbf{Z})$ is a function on the space $[0,1]$, that actually sits in $L^2([0,1])$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Find the Fourier transform $\\hat{f}(n)$ for the function $f(t)$ on the unit interval defined as\n",
    "$$ f(t) = \n",
    "\\left\\{\n",
    "\t\\begin{array}{ll}\n",
    "\t\t1  & \\mbox{if } 0 \\leq t < 1/2  \\\\\n",
    "\t\t-1 & \\mbox{if } 1/2 \\leq t  \\leq 1\n",
    "\t\\end{array}\n",
    "\\right.$$\n",
    "Check that the el-two norm of $f(t)$ is the same as the el-two norm of the sequence $\\hat{f}(n)$.\n",
    "\n",
    "This function is the basic Haar wavelet, so it is good to know something about its Fourier transform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier tranform on $\\mathbf{R}$\n",
    "\n",
    "Quickly, the Fourier transform of function on the real line is also a function on the real line. The transform is defined as\n",
    "$$\\hat{f}(\\omega) = \\int_{-\\infty}^\\infty f(t) e^{-2\\pi i \\omega t} dt. $$\n",
    "To recover a function from its Fourier transform, you write the same integral, but with a sign change in the exponential argument. (And the integration variable changes.)\n",
    "$$f(t) = \\int_{-\\infty}^\\infty \\hat{f}(\\omega) e^{2\\pi i \\omega t} d\\omega. $$\n",
    "\n",
    "It preserves inner products and el-two norm, so\n",
    "$$\\langle f, g \\rangle = \\langle \\hat{f}, \\hat{g} \\rangle$$ and\n",
    "$$ ||f||_2 = ||\\hat{f}||_2.$$\n",
    "\n",
    "The results are really nice - the only hard part is proving them!\n",
    "\n",
    "Again, with careful analysis, you can show this works for function $f$ in $L^2(\\mathbf{R})$ and the transform function $\\hat{f}$ also lives in $L^2(\\mathbf{R})$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Find the Fourier transform $\\hat{f}(\\omega)$ for the function $f(t)$ on the real line $\\mathbf{R}$ defined as\n",
    "$$ f(t) = \n",
    "\\left\\{\n",
    "\t\\begin{array}{ll}\n",
    "\t\t1  & \\mbox{if } -1 \\leq t < 1  \\\\\n",
    "\t\t0 & \\mbox{otherwise } \n",
    "\t\\end{array}\n",
    "\\right.$$\n",
    "Check that the el-two norm of $f(t)$ is the same as the el-two norm of the function $\\hat{f}(\\omega)$.\n",
    "\n",
    "You should get a sinc function, if all goes well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier transform on $\\{ 0, 1, 2, \\ldots, N-1\\}$\n",
    "\n",
    "Well, you think this should be easy. And in fact, it kind of is easy. It's all finite dimensional, so we don't have to worry about limits and stuff.\n",
    "\n",
    "Let's write our sequences as functions, like $a(0), a(1), a(2),\\ldots, a(N-1)$. \n",
    "\n",
    "We now form a basis by defining $N$ functions, labeled $e_0, e_1, e_2, \\ldots, e_{N-1}.$ The values they take are:\n",
    "$$e_k(n) = \\frac{1}{\\sqrt{N}} e^{2\\pi i nk/N} \\mbox{for } n=0,1,2,\\ldots, N-1.$$\n",
    "The point of the square root $N$ is to make these each a unit vector. They form an orthonormal basis as we can compute the inner products of an $e_j$ with an $e_k$ and see they are zero when $j=k$.\n",
    "\n",
    "This just takes a little algebra (I'll do it in class.)\n",
    "\n",
    "Then the Fourier transform of function $a$ is defined as\n",
    "$$\\hat{a}(k) = \\langle a,e_k\\rangle = \\frac{1}{\\sqrt{N}}\\sum_n a(n) e^{-2\\pi i nk/N}.$$\n",
    "\n",
    "Since we have an orthonormal basis, we can recover the function (vector) $a$ from its coefficients, so\n",
    "$$ a = \\sum_k \\hat{a}(k) e_k$$ or more completely,\n",
    "$$ a(n) = \\frac{1}{\\sqrt{N}}\\sum_k \\hat{a}(k) e^{2\\pi i nk/N}.$$\n",
    "\n",
    "Notice the forward and inverse transform look very similar, except we change the summation index, and we flip the sign in the complex exponential.\n",
    "\n",
    "Again, inner products, and el-two norms are preserved. (Why? Think about orthogonal bases.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution\n",
    "\n",
    "Are we ready to talk about convolution and Fourier transforms??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haar transform - do this in next lecture.\n",
    "\n",
    "- on a discrete space\n",
    "- on an interval\n",
    "- on the real line\n",
    "- just a quick intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
