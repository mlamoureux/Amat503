{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMAT503:  Lecture 11\n",
    "\n",
    "February 13, 2018.\n",
    "\n",
    "Michael Lamoureux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HEADS' UP!\n",
    "\n",
    "I will be using [Jupyter notebooks](https://jupyter.org) in this classroom, to combine text, math, and graphics. \n",
    "\n",
    "Students can access Jupyter at [ucalgary.syzygy.ca](https://ucalgary.syzygy.ca)\n",
    "\n",
    "An eBook on how to use syzygy is here: [intro.syzygy.ca](http://intro.syzygy.ca)\n",
    "\n",
    "Lecture notes, code, assignments, etc are available on a git repo: [github.com/mlamoureux](https://github.com/mlamoureux)\n",
    "\n",
    "The textbnook for the course is available electronically\n",
    "[here](https://ucalgary.summon.serialssolutions.com/#!/#!%2Fsearch%3FbookMark=ePnHCXMwhZ3bCoJAEIYNvCjrGcq6CLoQFMLoNjN6gO4H6QBSWLRrh7fvH2ddC4QuxQ_Fw87-M7v7r-e4yFuPHXFTYoMxiNIYSbV43SxC_EMRdyEeV8mQFIlTMnQJOl9ogW5dIGGvc2RuPcdf52hBkJD-M-PNGLSvvzQdvs3AcfW9RDQdbdJdsg2MheubTAWEeBZXHLHXXiBEs6iByiIveOdjKvcR8YIWZChLhHZ2au87M-EzdUbIQTjSih6XahhT0c_zgR0Lq7ITslyyTPPMYKbC1FGfqkuZaZiUrhLId-gLgEMBZfCYbuI8QVFYjZPy9pmTVkC_dCvULKiyqL2VgbiIcrja03KI5h3PGfr3aj8nd5KS)\n",
    "\n",
    "or [here](https://proquest-safaribooksonline-com.ezproxy.lib.ucalgary.ca/9780470183113?uicode=ucalgary).\n",
    "Thanks to Phil for pointing this out. \n",
    "\n",
    "\n",
    "One of the links should take any student to the ucalgary login page and then to the web version of the book after they successfully login."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Some startup commands\n",
    "\n",
    "%matplotlib inline\n",
    "from numpy import * \n",
    "from scipy import *\n",
    "from matplotlib.pyplot import *\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- We will look at a couple of applications of wavelets\n",
    "- Data compression\n",
    "- Noise reduction\n",
    "- In both 1D and 2D \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data compression\n",
    "\n",
    "Back in the day (when I was young!) people worried a lot about data compression. Computer files could be big, but storage media were small (floppy disks) or expensive (racks of hard drives or tapes) and transmitted data over phone lines was slow (e.g. 110 bits per second!). \n",
    "\n",
    "Now-a-days, storage is cheap (a 16 gigabyte flash drive costs 20 bucks), transmission is fast (100 megabit/second ethernet networks) but people still worry about data compression! Mainly because computer files have gotten bigger (think of high definition digital video) and data transmission needs have changed (think cloud computing, where your data and compute resources are located far away from you and your laptop, or think of Spotify, iTunes and Netflix, where you want to stream your digital media). \n",
    "\n",
    "So we still have to think about compressing data. \n",
    "\n",
    "One key idea in compression it to encode your data efficiently. For instance if you want to encode the following text (say, someting that no one can hear you scream in space):\n",
    "- \"AAAAAAAAAAAAHHHHHHHHHHHHHHHH\"\n",
    "\n",
    "we notice there are a bunch \"A\"s and a bunch of \"H\"s. The standard text encoding is to convert each character into an 8 bit ASCII character and record this as a string of $224 = 8*28$ binary digits.  \n",
    "\n",
    "In the Unicode standard, it gets worse: 16 bits per character, so 448 binary digits are required.\n",
    "\n",
    "A smarter way is to recognize that there are only 2 characters in this message, an \"A\" and an \"H\" which we can encode as single bits 0 or 1. So our message reduces to only 28 bits, namely:\n",
    "- \"0000000000001111111111111111\"\n",
    "\n",
    "This is a saving of a factor of 8 (or 16, for Unicode).\n",
    "\n",
    "Now of course we have to send a \"dictionary\" of information tell the reader how to decode that sequence of zeros and ones, but hopefully that dictionary does not take up much space, compared to the message.\n",
    "\n",
    "This is the key behind a lot of compression: look at the set of values/characters you want to store or send, and encode each character as a short string of bits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huffman compression\n",
    "\n",
    "Since we have a Huffman in the class, we should talk about Huffman compression! Actually, it is in the text and is a key workhorse for data compression.\n",
    "\n",
    "- my first use\n",
    "- using few bits for common characters\n",
    "- building trees.\n",
    "\n",
    "Example:\n",
    "- \"AAAAAAAAAAAARRRRGGGG\"\n",
    "\n",
    "Has lots of A's. So encode that with 0. A bit string that starts with 1 will mean \"here comes a R or a G.  So maybe 10 represents R, and 11 represents G. The above string becomes\n",
    "- \"000000000000 10 10 10 10 11 11 11 11\"\n",
    "\n",
    "Or, without the spaces:\n",
    "- \"0000000000001010101011111111\"\n",
    "\n",
    "Total number of bits is 12 + 8*2 = 28.\n",
    "\n",
    "Number of bits per character is 28/20 = 1.4 bits per character.\n",
    "So, pretty efficient. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy\n",
    "\n",
    "$$ En = \\sum_l p_k \\log_2 (\\frac{1}{p_k}). $$\n",
    "\n",
    "- the $p_k$ are fractions, summing to 1\n",
    "- this is a weighted average\n",
    "- message contains $N$ different characters, the k-th one appears a certain number of times, say the fraction $p_k$ of  the total. \n",
    "- $\\log_2 (\\frac{1}{p_k})$ represents how many bits needed to encode the k-th character. A frequent character should be encoded in as few bits as possible, to save space. Rare characters can use lots of bits, since they don't show up often.\n",
    "- the entropy is a measure of the average number of bits per character required to encode the message\n",
    "\n",
    "Shannon asked von Neumann what to call this sum. Johnnie say \"call it entropy because nobody knows what entropy is anyway.\" (check?)\n",
    "\n",
    "\n",
    "When is $En$ maximized? Minimized?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding real numbers\n",
    "\n",
    "- real numbers are not characters\n",
    "- but stored in computer as strings of bits\n",
    "- could apply Huffman to these, but not likely to succeed.\n",
    "\n",
    "In practice\n",
    "- data values lie in some range. \n",
    "- e.g. sound $-1< x_n <1$, B/W pixels $0 \\leq x_n < 256$\n",
    "- can quantize the data to finite precision.\n",
    "- e.g. sound in 8 bit (lo-fi) to 16 bit (hi-fi), pixels in 8 bit. \n",
    "- introduces quantization error, that typical appears as low intensity white noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise reduction\n",
    "\n",
    "\n",
    "Noise model:\n",
    "$$ y = v+e$$\n",
    "\n",
    "Apply wavelet transform:\n",
    "$$Z = Wy = Wv + We$$\n",
    "\n",
    "Check that $\\sigma$ for noise term does not change when applying wavelet transform (e.g. Haar)\n",
    "\n",
    "Signals are sparse -- detail portion will get small, but noise does not.\n",
    "\n",
    "So reduce those coefficients that are about the size of the noise..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
